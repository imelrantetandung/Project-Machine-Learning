{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a94bfd46-7c8c-4e75-8d3b-b4ae37aa8742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and preprocessing artifacts loaded successfully.\n",
      "Launching Gradio Interface...\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1. IMPORTS AND GLOBAL ARTIFACT LOADING\n",
    "# ============================================================\n",
    "# Pastikan Anda sudah menjalankan: !pip install pandas numpy xgboost joblib gradio pickle-mixin\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import pickle\n",
    "import joblib \n",
    "\n",
    "# XGBRegressor must be imported for joblib to load the model correctly\n",
    "from xgboost import XGBRegressor \n",
    "\n",
    "# --- Global Constants (Fallback values and feature list used during training) ---\n",
    "# NOTE: If the median year changes during training, update this constant manually!\n",
    "GLOBAL_YEAR_MEDIAN = 2004.0 \n",
    "features = [\"  num_pages\", \"language_code\", \"publisher\", \"authors\", \n",
    "            \"log_ratings_count\", \"log_reviews_count\", \"year\"]\n",
    "label_cols = ['language_code', 'publisher', 'authors']\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. CUSTOM PREPROCESSING CLASS DEFINITIONS\n",
    "# (Must match the definitions used in the training notebook)\n",
    "# ============================================================\n",
    "\n",
    "class CustomLabelEncoder:\n",
    "    def __init__(self):\n",
    "        self.classes_ = []\n",
    "        self._mapping = {}\n",
    "\n",
    "    def fit(self, series):\n",
    "        self.classes_ = series.unique().tolist()\n",
    "        self._mapping = {val: i for i, val in enumerate(self.classes_)}\n",
    "        return self\n",
    "\n",
    "    def transform(self, series):\n",
    "        return series.apply(lambda x: self._mapping.get(x, 0))\n",
    "\n",
    "class CustomStandardScaler:\n",
    "    def __init__(self):\n",
    "        self.mean_ = None\n",
    "        self.std_ = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.mean_ = X.mean()\n",
    "        self.std_ = X.std()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        epsilon = 1e-6\n",
    "        return (X - self.mean_) / (self.std_ + epsilon)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. LOAD TRAINED MODEL AND ARTIFACTS\n",
    "# ============================================================\n",
    "try:\n",
    "    xgb_reg = joblib.load('xgb_regressor_model.joblib')\n",
    "    with open('encoders.pkl', 'rb') as f:\n",
    "        encoders = pickle.load(f)\n",
    "    # Scaler is loaded but not strictly necessary for XGBoost prediction\n",
    "    scaler = joblib.load('custom_scaler.joblib') \n",
    "    print(\"Model and preprocessing artifacts loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    # This message is critical if the user hasn't run the training notebook yet\n",
    "    print(\"FATAL ERROR: Could not find model or artifact files (e.g., .joblib, .pkl).\")\n",
    "    print(\"Please ensure the 'Book_Training.ipynb' has been run and saved the files to this directory.\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. PREDICTION FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def predict_next_book_rating(num_pages, publisher, language_code, authors, ratings_count, text_reviews_count, year):\n",
    "    \"\"\"\n",
    "    Predicts the average rating for a new book using the loaded artifacts.\n",
    "    \"\"\"\n",
    "    \n",
    "    data_dict = {\n",
    "        \"  num_pages\": num_pages,\n",
    "        \"publisher\": publisher,\n",
    "        \"language_code\": language_code,\n",
    "        \"authors\": authors,\n",
    "        \"ratings_count\": ratings_count,\n",
    "        \"text_reviews_count\": text_reviews_count,\n",
    "        \"year\": year\n",
    "    }\n",
    "    \n",
    "    new_df = pd.DataFrame([data_dict])\n",
    "\n",
    "    # 1. CATEGORICAL ENCODING (Uses loaded 'encoders')\n",
    "    for col in label_cols:\n",
    "        val = str(new_df[col].iloc[0]).strip()\n",
    "        enc = encoders.get(col)\n",
    "        \n",
    "        if enc is None: continue # Skip if encoder is missing\n",
    "            \n",
    "        # Map unseen labels to the first class (0)\n",
    "        if val not in enc.classes_:\n",
    "            val = enc.classes_[0]  \n",
    "        new_df[col] = enc.transform(pd.Series([val]))[0]\n",
    "\n",
    "    # 2. NUMERIC FEATURES & LOG TRANSFORM\n",
    "    new_df['log_ratings_count'] = np.log1p(float(new_df['ratings_count'].iloc[0]))\n",
    "    new_df['log_reviews_count'] = np.log1p(float(new_df['text_reviews_count'].iloc[0]))\n",
    "    \n",
    "    # 3. YEAR & num_pages (Force numeric)\n",
    "    try:\n",
    "        new_df['year'] = float(new_df['year'].iloc[0])\n",
    "    except:\n",
    "        new_df['year'] = GLOBAL_YEAR_MEDIAN\n",
    "    new_df['  num_pages'] = float(new_df['  num_pages'].iloc[0])\n",
    "\n",
    "    # 4. SELECT FEATURES (Must match feature order from training)\n",
    "    new_X = new_df[features].astype(float)\n",
    "\n",
    "    # 5. PREDICT \n",
    "    try:\n",
    "        pred_rating = xgb_reg.predict(new_X)[0]\n",
    "    except NameError:\n",
    "        return \"ERROR: Model object (xgb_reg) not found. Check artifact loading.\"\n",
    "        \n",
    "    final_rating = np.clip(pred_rating, 0.0, 5.0)\n",
    "\n",
    "    return f\"Predicted Average Rating: {final_rating:.2f} / 5.0\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. GRADIO UI IMPLEMENTATION AND LAUNCH\n",
    "# ============================================================\n",
    "\n",
    "input_components = [\n",
    "    gr.Number(label=\"Number of Pages\", value=400, precision=0),\n",
    "    gr.Textbox(label=\"Publisher (e.g., Random House)\", value=\"Scholastic\"),\n",
    "    gr.Textbox(label=\"Language Code (e.g., eng, fre)\", value=\"eng\"),\n",
    "    gr.Textbox(label=\"Authors (e.g., J.K. Rowling)\", value=\"J.K. Rowling\"),\n",
    "    gr.Number(label=\"Ratings Count (Total user ratings)\", value=50000, precision=0),\n",
    "    gr.Number(label=\"Text Reviews Count\", value=1500, precision=0),\n",
    "    gr.Number(label=\"Publication Year (e.g., 2005)\", value=2010, precision=0)\n",
    "]\n",
    "\n",
    "output_component = gr.Textbox(label=\"Prediction Result\")\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_next_book_rating,\n",
    "    inputs=input_components,\n",
    "    outputs=output_component,\n",
    "    title=\"ðŸ“š Book Average Rating Predictor (UI Notebook)\",\n",
    "    description=\"Enter the details of a new book to predict its average rating (0.0 - 5.0).\",\n",
    "    examples=[\n",
    "        [400, \"Scholastic\", \"eng\", \"J.K. Rowling\", 50000, 1500, 2010],\n",
    "        [800, \"Bantam Books\", \"eng\", \"George R.R. Martin\", 200000, 8000, 2011],\n",
    "        [150, \"Unknown\", \"fre\", \"Unknown Author\", 1000, 50, 1995]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Launching Gradio Interface...\")\n",
    "iface.launch(inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3abb72e-55aa-4443-b9b2-2819f58cc7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
