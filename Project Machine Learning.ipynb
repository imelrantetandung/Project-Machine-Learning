{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2467778d-b327-4608-b14b-edbade38328d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find model or artifact files. Please run the training notebook first.\n",
      "Launching Gradio Interface in the Jupyter Notebook...\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1. IMPORTS AND GLOBAL ARTIFACT LOADING\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import pickle\n",
    "import joblib \n",
    "\n",
    "# You need to import the Regressor class for joblib to load the model correctly\n",
    "from xgboost import XGBRegressor \n",
    "\n",
    "# --- Global Constants ---\n",
    "# This median is a fallback for new books with missing year data.\n",
    "# It should match the median calculated during training.\n",
    "GLOBAL_YEAR_MEDIAN = 2004.0 \n",
    "\n",
    "# --- Feature List (Must match the training features exactly) ---\n",
    "features = [\"  num_pages\", \"language_code\", \"publisher\", \"authors\", \n",
    "            \"log_ratings_count\", \"log_reviews_count\", \"year\"]\n",
    "label_cols = ['language_code', 'publisher', 'authors']\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. CUSTOM PREPROCESSING CLASS DEFINITIONS\n",
    "# (These must be defined so the loaded objects work correctly)\n",
    "# ============================================================\n",
    "\n",
    "# --- Custom Label Encoder ---\n",
    "class CustomLabelEncoder:\n",
    "    def __init__(self):\n",
    "        self.classes_ = []\n",
    "        self._mapping = {}\n",
    "\n",
    "    def fit(self, series):\n",
    "        self.classes_ = series.unique().tolist()\n",
    "        self._mapping = {val: i for i, val in enumerate(self.classes_)}\n",
    "        return self\n",
    "\n",
    "    def transform(self, series):\n",
    "        return series.apply(lambda x: self._mapping.get(x, 0))\n",
    "\n",
    "    def fit_transform(self, series):\n",
    "        self.fit(series)\n",
    "        return self.transform(series)\n",
    "\n",
    "# --- Custom Standard Scaler ---\n",
    "class CustomStandardScaler:\n",
    "    def __init__(self):\n",
    "        self.mean_ = None\n",
    "        self.std_ = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.mean_ = X.mean()\n",
    "        self.std_ = X.std()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        epsilon = 1e-6\n",
    "        return (X - self.mean_) / (self.std_ + epsilon)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. LOAD TRAINED MODEL AND ARTIFACTS\n",
    "# (Ensure these file paths are correct)\n",
    "# ============================================================\n",
    "try:\n",
    "    xgb_reg = joblib.load('xgb_regressor_model.joblib')\n",
    "    with open('encoders.pkl', 'rb') as f:\n",
    "        encoders = pickle.load(f)\n",
    "    scaler = joblib.load('custom_scaler.joblib')\n",
    "    print(\"Model and preprocessing artifacts loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: Could not find model or artifact files. Please run the training notebook first.\")\n",
    "    # Exit or use dummy objects if necessary, but this error message is most helpful.\n",
    "    # For execution in this environment, we'll proceed, but the user must handle this locally.\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. PREDICTION FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def predict_next_book_rating(num_pages, publisher, language_code, authors, ratings_count, text_reviews_count, year):\n",
    "    \"\"\"\n",
    "    Predicts the average rating for a new book using the loaded model and encoders.\n",
    "    \"\"\"\n",
    "    \n",
    "    data_dict = {\n",
    "        \"  num_pages\": num_pages,\n",
    "        \"publisher\": publisher,\n",
    "        \"language_code\": language_code,\n",
    "        \"authors\": authors,\n",
    "        \"ratings_count\": ratings_count,\n",
    "        \"text_reviews_count\": text_reviews_count,\n",
    "        \"year\": year\n",
    "    }\n",
    "    \n",
    "    new_df = pd.DataFrame([data_dict])\n",
    "\n",
    "    # 1. CATEGORICAL ENCODING\n",
    "    for col in label_cols:\n",
    "        val = str(new_df[col].iloc[0]).strip()\n",
    "        enc = encoders.get(col)\n",
    "        \n",
    "        # Safety check: if encoder is missing (shouldn't happen), skip\n",
    "        if enc is None:\n",
    "            continue\n",
    "            \n",
    "        # Map unseen labels to the first class (0)\n",
    "        if val not in enc.classes_:\n",
    "            val = enc.classes_[0]  \n",
    "        new_df[col] = enc.transform(pd.Series([val]))[0]\n",
    "\n",
    "    # 2. NUMERIC FEATURES & LOG TRANSFORM\n",
    "    new_df['log_ratings_count'] = np.log1p(float(new_df['ratings_count'].iloc[0]))\n",
    "    new_df['log_reviews_count'] = np.log1p(float(new_df['text_reviews_count'].iloc[0]))\n",
    "    \n",
    "    # 3. YEAR & num_pages (Force numeric)\n",
    "    try:\n",
    "        new_df['year'] = float(new_df['year'].iloc[0])\n",
    "    except:\n",
    "        new_df['year'] = GLOBAL_YEAR_MEDIAN # Use the fallback median constant\n",
    "    new_df['  num_pages'] = float(new_df['  num_pages'].iloc[0])\n",
    "\n",
    "    # 4. SELECT FEATURES\n",
    "    new_X = new_df[features].astype(float)\n",
    "\n",
    "    # 5. PREDICT (XGBoost uses unscaled X)\n",
    "    try:\n",
    "        pred_rating = xgb_reg.predict(new_X)[0]\n",
    "    except NameError:\n",
    "        # If model loading failed due to missing files, return an error message\n",
    "        return \"ERROR: Model not loaded correctly. Check the artifact file paths.\"\n",
    "        \n",
    "    # Clip the result to ensure it's a valid rating (0.0 to 5.0)\n",
    "    final_rating = np.clip(pred_rating, 0.0, 5.0)\n",
    "\n",
    "    return f\"Predicted Average Rating: {final_rating:.2f} / 5.0\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. GRADIO UI IMPLEMENTATION AND LAUNCH\n",
    "# ============================================================\n",
    "\n",
    "input_components = [\n",
    "    gr.Number(label=\"Number of Pages\", value=400, precision=0),\n",
    "    gr.Textbox(label=\"Publisher (e.g., Random House)\", value=\"Scholastic\"),\n",
    "    gr.Textbox(label=\"Language Code (e.g., eng, fre)\", value=\"eng\"),\n",
    "    gr.Textbox(label=\"Authors (e.g., J.K. Rowling)\", value=\"J.K. Rowling\"),\n",
    "    gr.Number(label=\"Ratings Count (Total user ratings)\", value=50000, precision=0),\n",
    "    gr.Number(label=\"Text Reviews Count\", value=1500, precision=0),\n",
    "    gr.Number(label=\"Publication Year (e.g., 2005)\", value=2010, precision=0)\n",
    "]\n",
    "\n",
    "output_component = gr.Textbox(label=\"Prediction Result\")\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_next_book_rating,\n",
    "    inputs=input_components,\n",
    "    outputs=output_component,\n",
    "    title=\"ðŸ“š Book Average Rating Predictor (UI Notebook)\",\n",
    "    description=\"Enter the details of a new book to predict its average rating (0.0 - 5.0).\",\n",
    "    examples=[\n",
    "        [400, \"Scholastic\", \"eng\", \"J.K. Rowling\", 50000, 1500, 2010],\n",
    "        [800, \"Bantam Books\", \"eng\", \"George R.R. Martin\", 200000, 8000, 2011],\n",
    "        [150, \"Unknown\", \"fre\", \"Unknown Author\", 1000, 50, 1995]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Launching Gradio Interface in the Jupyter Notebook...\")\n",
    "# Use 'inline=True' for better display within the notebook environment\n",
    "iface.launch(inline=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
