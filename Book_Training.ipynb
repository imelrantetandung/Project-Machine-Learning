{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79cbc55b-67cb-4ebb-828f-6b0173cd938b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Model Training ---\n",
      "Model training complete.\n",
      "\n",
      "--- Model Evaluation (Test Set) ---\n",
      "MAE: 0.1991\n",
      "RMSE: 0.2589\n",
      "R²: 0.1955\n",
      "\n",
      "--- Saving Artifacts ---\n",
      "Saved: xgb_regressor_model.joblib\n",
      "Saved: encoders.pkl\n",
      "Saved: custom_scaler.joblib\n",
      "\n",
      "Training notebook finished. Ready to use the UI notebook.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1. SETUP: INSTALL & IMPORT LIBRARIES\n",
    "# ============================================================\n",
    "# Pastikan Anda sudah menjalankan: !pip install pandas numpy xgboost scikit-learn joblib pickle-mixin\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "import pickle\n",
    "import joblib \n",
    "\n",
    "from xgboost import XGBRegressor \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score \n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. CUSTOM PREPROCESSING FUNCTIONS (Necessary for saving/loading)\n",
    "# ============================================================\n",
    "\n",
    "# --- Custom Label Encoder ---\n",
    "class CustomLabelEncoder:\n",
    "    \"\"\"A minimal class to fit and transform categorical data to integers.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.classes_ = []\n",
    "        self._mapping = {}\n",
    "\n",
    "    def fit(self, series):\n",
    "        self.classes_ = series.unique().tolist()\n",
    "        self._mapping = {val: i for i, val in enumerate(self.classes_)}\n",
    "        return self\n",
    "\n",
    "    def transform(self, series):\n",
    "        return series.apply(lambda x: self._mapping.get(x, 0))\n",
    "\n",
    "    def fit_transform(self, series):\n",
    "        self.fit(series)\n",
    "        return self.transform(series)\n",
    "\n",
    "# --- Custom Standard Scaler ---\n",
    "class CustomStandardScaler:\n",
    "    \"\"\"A minimal class to fit and transform data using Z-score standardization.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.mean_ = None\n",
    "        self.std_ = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.mean_ = X.mean()\n",
    "        self.std_ = X.std()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        epsilon = 1e-6\n",
    "        return (X - self.mean_) / (self.std_ + epsilon)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "# --- Custom Train-Test Split (Simplified) ---\n",
    "def custom_train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    if random_state is not None:\n",
    "        random.seed(random_state)\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    df_combined = X.copy()\n",
    "    df_combined['__target__'] = y.values\n",
    "    \n",
    "    indices = df_combined.index.tolist()\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    test_count = int(len(indices) * test_size)\n",
    "    test_indices = indices[:test_count]\n",
    "    train_indices = indices[test_count:]\n",
    "    \n",
    "    X_train = df_combined.loc[train_indices, X.columns]\n",
    "    X_test = df_combined.loc[test_indices, X.columns]\n",
    "    y_train = df_combined.loc[train_indices, '__target__']\n",
    "    y_test = df_combined.loc[test_indices, '__target__']\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. DATA LOADING AND PRE-PROCESSING\n",
    "# ============================================================\n",
    "df = pd.read_csv(\n",
    "    \"books.csv\",\n",
    "    engine=\"python\",\n",
    "    on_bad_lines=\"skip\"\n",
    ")\n",
    "\n",
    "# Clean Target Variable (Regression Target)\n",
    "df['average_rating'] = pd.to_numeric(df['average_rating'], errors='coerce') \n",
    "df = df[df['average_rating'].notnull()]\n",
    "df = df[df['average_rating'] > 0.0].copy()\n",
    "\n",
    "# Fix missing values\n",
    "df['publisher'] = df['publisher'].fillna(\"Unknown\")\n",
    "df['language_code'] = df['language_code'].fillna(\"Unknown\")\n",
    "df['authors'] = df['authors'].fillna(\"Unknown\")\n",
    "\n",
    "# Extract year\n",
    "df['year'] = pd.to_datetime(df['publication_date'], errors='coerce').dt.year\n",
    "df['year'] = df['year'].fillna(df['year'].median())\n",
    "GLOBAL_YEAR_MEDIAN = df['year'].median() # Capture median for UI notebook\n",
    "\n",
    "# Log-transform \n",
    "df['log_ratings_count'] = np.log1p(df['ratings_count'])\n",
    "df['log_reviews_count'] = np.log1p(df['text_reviews_count'])\n",
    "\n",
    "# Label encode\n",
    "label_cols = ['language_code', 'publisher', 'authors']\n",
    "encoders = {}\n",
    "\n",
    "for col in label_cols:\n",
    "    enc = CustomLabelEncoder()\n",
    "    df[col] = enc.fit_transform(df[col].astype(str).str.strip())\n",
    "    encoders[col] = enc\n",
    "\n",
    "# Feature/Target Selection and Split\n",
    "features = [\"  num_pages\", \"language_code\", \"publisher\", \"authors\", \n",
    "            \"log_ratings_count\", \"log_reviews_count\", \"year\"]\n",
    "\n",
    "X = df[features]\n",
    "y = df['average_rating'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = custom_train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling (Fit the scaler, though XGBoost uses unscaled data)\n",
    "scaling_cols = [\"  num_pages\", \"log_ratings_count\", \"log_reviews_count\", \"year\"]\n",
    "scaler = CustomStandardScaler()\n",
    "scaler.fit(X_train[scaling_cols]) \n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. TRAIN MODEL (XGBoost Regressor)\n",
    "# ============================================================\n",
    "print(\"\\n--- Starting Model Training ---\")\n",
    "xgb_reg = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42\n",
    ")\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. EVALUATION (Optional, but good practice)\n",
    "# ============================================================\n",
    "preds = xgb_reg.predict(X_test)\n",
    "preds = np.clip(preds, 0.0, 5.0)\n",
    "\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds)) \n",
    "r2 = r2_score(y_test, preds)\n",
    "\n",
    "print(\"\\n--- Model Evaluation (Test Set) ---\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. SAVE MODEL AND PREPROCESSING ARTIFACTS (CRITICAL STEP)\n",
    "# ============================================================\n",
    "print(\"\\n--- Saving Artifacts ---\")\n",
    "# 1. Save the trained XGBoost Regressor model\n",
    "joblib.dump(xgb_reg, 'xgb_regressor_model.joblib')\n",
    "print(\"Saved: xgb_regressor_model.joblib\")\n",
    "\n",
    "# 2. Save the custom encoders dictionary\n",
    "with open('encoders.pkl', 'wb') as f:\n",
    "    pickle.dump(encoders, f)\n",
    "print(\"Saved: encoders.pkl\")\n",
    "\n",
    "# 3. Save the CustomStandardScaler object\n",
    "joblib.dump(scaler, 'custom_scaler.joblib')\n",
    "print(\"Saved: custom_scaler.joblib\")\n",
    "print(\"\\nTraining notebook finished. Ready to use the UI notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9115f197-8d04-4ec1-8bf6-40b6adaf9021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
